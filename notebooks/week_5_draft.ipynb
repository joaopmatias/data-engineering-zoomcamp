{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/24 23:52:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local[2]\")\n",
    "    .appName(\"test\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "! cd ../data/fhvhv && wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:02:41</td>\n",
       "      <td>2021-06-01 00:07:46</td>\n",
       "      <td>174</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:16:16</td>\n",
       "      <td>2021-06-01 00:21:14</td>\n",
       "      <td>32</td>\n",
       "      <td>254</td>\n",
       "      <td>N</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:27:01</td>\n",
       "      <td>2021-06-01 00:42:11</td>\n",
       "      <td>240</td>\n",
       "      <td>127</td>\n",
       "      <td>N</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:46:08</td>\n",
       "      <td>2021-06-01 00:53:45</td>\n",
       "      <td>127</td>\n",
       "      <td>235</td>\n",
       "      <td>N</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-06-01 00:45:42</td>\n",
       "      <td>2021-06-01 01:03:33</td>\n",
       "      <td>144</td>\n",
       "      <td>146</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-06-01 00:18:15</td>\n",
       "      <td>2021-06-01 00:25:47</td>\n",
       "      <td>49</td>\n",
       "      <td>17</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-06-01 00:33:06</td>\n",
       "      <td>2021-06-01 00:42:46</td>\n",
       "      <td>49</td>\n",
       "      <td>225</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-06-01 00:46:27</td>\n",
       "      <td>2021-06-01 00:56:50</td>\n",
       "      <td>225</td>\n",
       "      <td>177</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:48:06</td>\n",
       "      <td>2021-06-01 01:04:10</td>\n",
       "      <td>209</td>\n",
       "      <td>45</td>\n",
       "      <td>N</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B02875</td>\n",
       "      <td>2021-06-01 00:18:54</td>\n",
       "      <td>2021-06-01 00:26:14</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>N</td>\n",
       "      <td>B02875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num      pickup_datetime     dropoff_datetime  \\\n",
       "0               B02764  2021-06-01 00:02:41  2021-06-01 00:07:46   \n",
       "1               B02764  2021-06-01 00:16:16  2021-06-01 00:21:14   \n",
       "2               B02764  2021-06-01 00:27:01  2021-06-01 00:42:11   \n",
       "3               B02764  2021-06-01 00:46:08  2021-06-01 00:53:45   \n",
       "4               B02510  2021-06-01 00:45:42  2021-06-01 01:03:33   \n",
       "5               B02510  2021-06-01 00:18:15  2021-06-01 00:25:47   \n",
       "6               B02510  2021-06-01 00:33:06  2021-06-01 00:42:46   \n",
       "7               B02510  2021-06-01 00:46:27  2021-06-01 00:56:50   \n",
       "8               B02764  2021-06-01 00:48:06  2021-06-01 01:04:10   \n",
       "9               B02875  2021-06-01 00:18:54  2021-06-01 00:26:14   \n",
       "\n",
       "   PULocationID  DOLocationID SR_Flag Affiliated_base_number  \n",
       "0           174            18       N                 B02764  \n",
       "1            32           254       N                 B02764  \n",
       "2           240           127       N                 B02764  \n",
       "3           127           235       N                 B02764  \n",
       "4           144           146       N                    NaN  \n",
       "5            49            17       N                    NaN  \n",
       "6            49           225       N                    NaN  \n",
       "7           225           177       N                    NaN  \n",
       "8           209            45       N                 B02764  \n",
       "9            80           256       N                 B02875  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(Path(\"../data/fhvhv/fhvhv_tripdata_2021-06.csv.gz\").resolve(), nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num      object\n",
       "pickup_datetime           object\n",
       "dropoff_datetime          object\n",
       "PULocationID               int64\n",
       "DOLocationID               int64\n",
       "SR_Flag                   object\n",
       "Affiliated_base_number    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(Path(\"../data/fhvhv/fhvhv_tripdata_2021-06.csv.gz\").resolve(), nrows=10).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "schema = types.StructType([\n",
    "    types.StructField(\"dispatching_base_num\", types.StringType(), True),\n",
    "    types.StructField(\"pickup_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"dropoff_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"PULocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"DOLocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"SR_Flag\", types.StringType(), True),\n",
    "    types.StructField(\"Affiliated_base_number\", types.StringType(), True),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "df = (\n",
    "    spark\n",
    "    .read\n",
    "    .option(\"header\", \"true\")\n",
    "    .schema(schema)\n",
    "    .csv(Path(\"../data/fhvhv/fhvhv_tripdata_2021-06.csv.gz\").resolve().as_posix())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 6, 1, 0, 2, 41), dropoff_datetime=datetime.datetime(2021, 6, 1, 0, 7, 46), PULocationID=174, DOLocationID=18, SR_Flag='N', Affiliated_base_number='B02764'),\n",
       " Row(dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 6, 1, 0, 16, 16), dropoff_datetime=datetime.datetime(2021, 6, 1, 0, 21, 14), PULocationID=32, DOLocationID=254, SR_Flag='N', Affiliated_base_number='B02764'),\n",
       " Row(dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 6, 1, 0, 27, 1), dropoff_datetime=datetime.datetime(2021, 6, 1, 0, 42, 11), PULocationID=240, DOLocationID=127, SR_Flag='N', Affiliated_base_number='B02764'),\n",
       " Row(dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 6, 1, 0, 46, 8), dropoff_datetime=datetime.datetime(2021, 6, 1, 0, 53, 45), PULocationID=127, DOLocationID=235, SR_Flag='N', Affiliated_base_number='B02764'),\n",
       " Row(dispatching_base_num='B02510', pickup_datetime=datetime.datetime(2021, 6, 1, 0, 45, 42), dropoff_datetime=datetime.datetime(2021, 6, 1, 1, 3, 33), PULocationID=144, DOLocationID=146, SR_Flag='N', Affiliated_base_number=None)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(\n",
    "    df\n",
    "    .repartition(12)\n",
    "    .write\n",
    "    .parquet(Path(\"../data/fhvhv/2021/06/\").resolve().as_posix())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 290748\n",
      "-rw-r--r-- 1 joaopmatias joaopmatias        0 Feb 25 00:38 _SUCCESS\n",
      "-rw-r--r-- 1 joaopmatias joaopmatias 24801840 Feb 25 00:38 part-00000-b8432052-872e-4b39-9551-e2789418d982-c000.snappy.parquet\n",
      "-rw-r--r-- 1 joaopmatias joaopmatias 24799764 Feb 25 00:38 part-00001-b8432052-872e-4b39-9551-e2789418d982-c000.snappy.parquet\n",
      "-rw-r--r-- 1 joaopmatias joaopmatias 24813665 Feb 25 00:38 part-00002-b8432052-872e-4b39-9551-e2789418d982-c000.snappy.parquet\n",
      "-rw-r--r-- 1 joaopmatias joaopmatias 24816657 Feb 25 00:38 part-00003-b8432052-872e-4b39-9551-e2789418d982-c000.snappy.parquet\n",
      "-rw-r--r-- 1 joaopmatias joaopmatias 24807133 Feb 25 00:38 part-00004-b8432052-872e-4b39-9551-e2789418d982-c000.snappy.parquet\n",
      "-rw-r--r-- 1 joaopmatias joaopmatias 24800815 Feb 25 00:38 part-00005-b8432052-872e-4b39-9551-e2789418d982-c000.snappy.parquet\n",
      "-rw-r--r-- 1 joaopmatias joaopmatias 24812906 Feb 25 00:38 part-00006-b8432052-872e-4b39-9551-e2789418d982-c000.snappy.parquet\n",
      "-rw-r--r-- 1 joaopmatias joaopmatias 24809398 Feb 25 00:38 part-00007-b8432052-872e-4b39-9551-e2789418d982-c000.snappy.parquet\n",
      "-rw-r--r-- 1 joaopmatias joaopmatias 24814315 Feb 25 00:38 part-00008-b8432052-872e-4b39-9551-e2789418d982-c000.snappy.parquet\n",
      "-rw-r--r-- 1 joaopmatias joaopmatias 24810739 Feb 25 00:38 part-00009-b8432052-872e-4b39-9551-e2789418d982-c000.snappy.parquet\n",
      "-rw-r--r-- 1 joaopmatias joaopmatias 24810799 Feb 25 00:38 part-00010-b8432052-872e-4b39-9551-e2789418d982-c000.snappy.parquet\n",
      "-rw-r--r-- 1 joaopmatias joaopmatias 24803713 Feb 25 00:38 part-00011-b8432052-872e-4b39-9551-e2789418d982-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "! ls -l ../data/fhvhv/2021/06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.55 ms, sys: 1.17 ms, total: 10.7 ms\n",
      "Wall time: 24 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "452470"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "(\n",
    "    df\n",
    "    .withColumn(\"pickup_date\", F.to_date(F.col(\"pickup_datetime\")))\n",
    "    .filter(F.col(\"pickup_date\") == \"2021-06-15\")\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 ms, sys: 4.88 ms, total: 17.9 ms\n",
      "Wall time: 28.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(max(duration)=datetime.timedelta(days=2, seconds=67964))]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(\n",
    "    df\n",
    "    .withColumn(\"pickup_date\", F.to_date(F.col(\"pickup_datetime\")))\n",
    "    .withColumn(\"duration\", F.col(\"dropoff_datetime\") - F.col(\"pickup_datetime\"))\n",
    "    .groupBy()\n",
    "    .agg({\"duration\": \"max\"})\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "! cd ../data && wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone = (\n",
    "    spark\n",
    "    .read\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(Path(\"../data/taxi_zone_lookup.csv\").resolve().as_posix())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(LocationID='1', Borough='EWR', Zone='Newark Airport', service_zone='EWR')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 100:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+--------------------+\n",
      "|PULocationID| count|                Zone|\n",
      "+------------+------+--------------------+\n",
      "|          61|231279| Crown Heights North|\n",
      "|          79|221244|        East Village|\n",
      "|         132|188867|         JFK Airport|\n",
      "|          37|187929|      Bushwick South|\n",
      "|          76|186780|       East New York|\n",
      "|         231|164344|TriBeCa/Civic Center|\n",
      "|         138|161596|   LaGuardia Airport|\n",
      "|         234|158937|            Union Sq|\n",
      "|         249|154698|        West Village|\n",
      "|           7|152493|             Astoria|\n",
      "|         148|151020|     Lower East Side|\n",
      "|          68|147673|        East Chelsea|\n",
      "|          42|146402|Central Harlem North|\n",
      "|         255|143683|Williamsburg (Nor...|\n",
      "|         181|143594|          Park Slope|\n",
      "|         225|141427|  Stuyvesant Heights|\n",
      "|          48|139611|        Clinton East|\n",
      "|         246|139431|West Chelsea/Huds...|\n",
      "|          17|138428|             Bedford|\n",
      "|         170|137879|         Murray Hill|\n",
      "+------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 18.3 ms, sys: 172 µs, total: 18.5 ms\n",
      "Wall time: 21.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/25 02:11:28 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/blockmgr-ed68d22c-75cc-4be4-a4b7-33528f8f946d. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /tmp/blockmgr-ed68d22c-75cc-4be4-a4b7-33528f8f946d\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:374)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:370)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:370)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:365)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2026)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:95)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2140)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2140)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:660)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(\n",
    "    df\n",
    "    .select(\"PULocationID\")\n",
    "    .groupBy(\"PULocationID\")\n",
    "    .count()\n",
    "    .join(\n",
    "        df_zone\n",
    "        .select(F.col(\"LocationID\").alias(\"PUlocationID\"), F.col(\"Zone\")),\n",
    "        on=\"PUlocationID\")\n",
    "    .orderBy(\"count\", ascending=False)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3492244e9cc9df01040d6642710c3829c05b683ad2fbce1bf937232fb1ed411f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
